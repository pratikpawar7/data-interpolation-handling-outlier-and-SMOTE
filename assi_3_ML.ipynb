{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9184b-d7d1-4469-9d77-6ec0ab79bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values.\n",
    "'''\n",
    "\n",
    "\n",
    "Missing values in a dataset refer to the absence of a particular value or data point in one or more\n",
    "columns of a row. There are various reasons why data may be missing, such as data corruption, human error,\n",
    "or system failure.\n",
    "\n",
    "It is essential to handle missing values because they can adversely impact the accuracy and reliability\n",
    "of any analysis or machine learning model developed using the dataset. If missing values are ignored, \n",
    "they can lead to biased or incorrect conclusions, which may result in poor business decisions or ineffective models.\n",
    "\n",
    "Some algorithms that are not affected by missing values include tree-based algorithms such as decision trees, \n",
    "random forests, and gradient boosting, as well as some clustering algorithms such as K-means clustering.\n",
    "These algorithms can work with missing values by ignoring the missing values while splitting the dataset, \n",
    "or by using surrogate variables to approximate missing values during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f6c5a9-a9e8-4642-8cc0-af5d7960470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "3  4.0  8.0  12\n",
      "    C\n",
      "0   9\n",
      "1  10\n",
      "2  11\n",
      "3  12\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "'''\n",
    "\n",
    "# 1 .Deleting rows or columns: If the missing values are very few, we can delete the corresponding rows or columns. Here's an example:\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, np.nan, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "})\n",
    "\n",
    "# Delete rows with missing values\n",
    "df_drop_row = df.dropna(axis=0)\n",
    "print(df_drop_row)\n",
    "\n",
    "# Delete columns with missing values\n",
    "df_drop_col = df.dropna(axis=1)\n",
    "print(df_drop_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc18019f-ef11-4a6f-b500-55dc0bcd46a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  5.0  10\n",
      "2  2.0  5.0  11\n",
      "3  4.0  8.0  12\n",
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  8.0  10\n",
      "2  4.0  8.0  11\n",
      "3  4.0  8.0  12\n"
     ]
    }
   ],
   "source": [
    "# 2.Forward or backward fill: We can propagate the last known value forward or backward. Here's an example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, np.nan, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "})\n",
    "\n",
    "# Forward fill\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "print(df_ffill)\n",
    "\n",
    "# Backward fill\n",
    "df_bfill = df.fillna(method='bfill')\n",
    "print(df_bfill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f040aa-971f-41eb-8f26-53d5f8be2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "'''\n",
    "\n",
    "\n",
    "one class has significantly more instances than the other class(es). \n",
    "For example, in a binary classification problem, if one class has 90% of the instances and\n",
    "the other class has only 10%, the data is said to be imbalanced.\n",
    "\n",
    "handling imbalanced data is essential to prevent biased model predictions and ensure that \n",
    "the model is equally effective at predicting all classes in the classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ec63f-21c6-4701-82e4-6e6acf2d0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down\u0002sampling are required.\n",
    "'''\n",
    "\n",
    "Up-sampling is the process of randomly replicating instances from the minority class to increase\n",
    "its representation in the dataset. This technique can be useful when the dataset has a significant\n",
    "class imbalance and the minority class has few instances.\n",
    "\n",
    "Down-sampling, on the other hand, is the process of randomly removing instances from the majority\n",
    "class to decrease its representation in the dataset. This technique can be useful when the majority \n",
    "class has a significantly larger number of instances than the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec6d97-5f7d-4312-b135-7f6b9b9a65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "'''\n",
    "\n",
    "\n",
    "Data augmentation is a technique used in machine learning to increase the amount of training data \n",
    "by creating new, artificial examples from the existing ones. It is commonly used when the size of\n",
    "the training dataset is small, and the models performance is limited due to the lack of data. \n",
    "Data augmentation can be applied to various types of data, including images, audio, text, and tabular data.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used \n",
    "for imbalanced datasets. It works by creating synthetic examples of the minority class by interpolating \n",
    "new examples along the line segments joining neighboring minority class examples. The SMOTE algorithm\n",
    "selects a random example from the minority class and then finds its k-nearest neighbors. It then \n",
    "generates new examples by interpolating between the selected example and its k-nearest neighbors.\n",
    "\n",
    "For example, suppose we have a dataset with two classes: class A has 100 samples, and class B has \n",
    "only 10 samples. The dataset is imbalanced, and the model performance is limited due to the lack\n",
    "of data for class B. In this case, we can use SMOTE to generate new synthetic examples of class B,\n",
    "which will balance the dataset and improve the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f7dfd-8218-46ff-8376-1c180657d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "'''\n",
    "\n",
    "Outliers are the data points that are significantly different from other data points in a dataset.\n",
    "They can occur due to various reasons such as measurement errors, data entry errors, or natural\n",
    "variation in data. Outliers can have a significant impact on the performance of machine learning\n",
    "models as they can influence the mean, variance, and standard deviation of a dataset.\n",
    "\n",
    "It is essential to handle outliers because they can distort the results of statistical analyses \n",
    "and can have a significant impact on the performance of machine learning models. Outliers can cause\n",
    "a model to overfit or underfit, which can lead to poor generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2196cf3-7fb4-4924-aa63-acba29d0e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "'''\n",
    "1.Deletion: One option is to simply delete the rows or columns that contain missing data.\n",
    "        This technique is called deletion, and there are two types of deletion: listwise deletion \n",
    "        (also called complete case analysis), which deletes any row with a missing value, and pairwise\n",
    "        deletion, which only deletes the specific missing values in a row or column.\n",
    "\n",
    "\n",
    "2.Imputation: Imputation involves estimating missing values based on the available data. \n",
    "        Some common imputation methods include mean, median, mode, and regression imputation\n",
    "\n",
    "3.Prediction: Another option is to use machine learning algorithms to predict missing values based \n",
    "            on the available data.\n",
    "\n",
    "4.Expert judgment: If none of the above techniques are suitable, expert judgment can be used to \n",
    "                estimate missing values based on the context of the data and the expertise of the analyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de65d1-7a61-4a34-a62a-dd8d2bd6a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?\n",
    "'''\n",
    "\n",
    "\n",
    "1.visual inspection: Plotting the data can sometimes reveal patterns in the missing data. \n",
    "        For example, if missing values tend to cluster around a certain range of values, it could suggest that\n",
    "        there is a pattern to the missing data.\n",
    "\n",
    "2.Correlation analysis: Correlation analysis can be used to determine if there is a relationship between\n",
    "        missing data and other variables in the dataset. If missing values are correlated with certain variables,\n",
    "        it could suggest that there is a pattern to the missing data.\n",
    "\n",
    "3.Missing data imputation: Imputing missing data and comparing the imputed values to the actual values \n",
    "        can give an indication of whether the missing data is missing at random or not. If the imputed values \n",
    "        are close to the actual values, it suggests that the missing data is missing at random.\n",
    "\n",
    "4.Statistical tests: Statistical tests such as Littles MCAR test or MAR test can be used to determine\n",
    "        if the missing data is missing completely at random (MCAR) or if there is a pattern to the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fbda10-2037-41ab-bec3-8e49cc61ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "'''\n",
    "\n",
    "\n",
    "Confusion Matrix: A confusion matrix can be used to visualize the performance of a model on a binary\n",
    "            classification problem. It displays the number of true positive, true negative, false positive,\n",
    "           and false negative predictions. From this, various performance metrics such as precision, recall,\n",
    "            and F1 score can be computed.\n",
    "\n",
    "Precision and Recall: Precision is the proportion of true positives among all predicted positives,\n",
    "        while recall is the proportion of true positives among all actual positives. These metrics\n",
    "        are often used in conjunction with each other to evaluate the performance of a model on imbalanced datasets.\n",
    "\n",
    "ROC Curve and AUC: The receiver operating characteristic (ROC) curve is a graphical representation of the \n",
    "        performance of a binary classifier. It plots the true positive rate (TPR) against the false positive rate \n",
    "        (FPR) for different classification thresholds. The area under the curve (AUC) is a scalar metric that\n",
    "        summarizes the overall performance of the classifier.\n",
    "\n",
    "Class weights: Many machine learning algorithms allow for assigning class weights to account for imbalanced datasets.\n",
    "            By giving a higher weight to the minority class, the model is incentivized to better classify examples from that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9693b09b-a74c-4ffe-a819-d9f02bead1fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (418650471.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?\n",
    "'''\n",
    "\n",
    "1.Random Under-Sampling: Randomly select a subset of data from the majority class to match the\n",
    "        number of samples in the minority class.\n",
    "\n",
    "2.Cluster-Based Under-Sampling: Cluster the majority class data and select samples from each \n",
    "        cluster to match the number of samples in the minority class.\n",
    "\n",
    "3.Tomek Links: Identify pairs of samples in the majority and minority classes that are close to \n",
    "        each other and remove the majority class samples.\n",
    "\n",
    "4.NearMiss Algorithm: This algorithm selects samples from the majority class that are closest to\n",
    "        the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081a564-10d1-4d8d-a794-21b48f8961f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fe3bc-481f-49aa-bba6-c93f8844753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?\n",
    "'''.\n",
    "\n",
    "1.SMOTE (Synthetic Minority Over-sampling Technique): This method creates synthetic samples for\n",
    "            the minority class by interpolating between existing minority class samples.\n",
    "\n",
    "2.ADASYN (Adaptive Synthetic Sampling): This method is similar to SMOTE but focuses on generating \n",
    "            more synthetic samples in regions of the feature space where the density of the minority \n",
    "            class is lower.\n",
    "\n",
    "3.Random oversampling: This method involves duplicating samples from the minority class randomly \n",
    "        until the classes are balanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf9679-d1e0-46df-98d6-55cbd0df184c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
